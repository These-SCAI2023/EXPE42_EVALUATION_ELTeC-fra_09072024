{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyM5MjibO6MWFqvboC3WYyJm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNctreQ7jion",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718784755225,
     "user_tz": -120,
     "elapsed": 19897,
     "user": {
      "displayName": "Camille F",
      "userId": "07170788391818516825"
     }
    },
    "outputId": "7e30dba2-2ab9-4626-8433-9b7af9bbb201",
    "ExecuteTime": {
     "end_time": "2024-10-26T07:21:19.914729Z",
     "start_time": "2024-10-26T07:21:19.438816Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "KF0-E6ezJHle"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "file_path = '/content/drive/My Drive/Colab Notebooks/Presentation20062024/ANNOTATION_ANNOTATEURICES/AA_annotations/CARRAUD/AA_CARRAUD_petite-Jeanne_Kraken-base_spaCy3.7.2-lg.csv'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file, delimiter=';')\n",
    "        rows = []"
   ],
   "metadata": {
    "id": "Cem1WhKfabWJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718784967359,
     "user_tz": -120,
     "elapsed": 260,
     "user": {
      "displayName": "Camille F",
      "userId": "07170788391818516825"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Chemin vers le dossier principal\n",
    "# root_dir = '/content/drive/My Drive/Colab Notebooks/Presentation20062024/ANNOTATION_ANNOTATEURICES'\n",
    "# output_dir = '/content/drive/My Drive/Colab Notebooks/Presentation20062024/ANNOTATION_ANNOTATEURICES_TRANSFORMED'\n",
    "\n",
    "root_dir = '../ANNOTATION_ANNOTATEURICES_v2'\n",
    "output_dir = '../ANNOTATION_ANNOTATEURICES_TRANSFORMED_V2'\n",
    "\n",
    "#Création du dossier de sortie s'il n'existe pas\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ],
   "metadata": {
    "id": "sqzZrpSEnNqX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718784984676,
     "user_tz": -120,
     "elapsed": 260,
     "user": {
      "displayName": "Camille F",
      "userId": "07170788391818516825"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-10-26T07:45:44.414404Z",
     "start_time": "2024-10-26T07:45:44.410750Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Fonction pour traiter chaque fichier CSV\n",
    "def process_csv_file(file_path, output_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file, delimiter=';')\n",
    "        rows = []\n",
    "\n",
    "        for row in reader:\n",
    "            token = row['Token']\n",
    "            label = row['Label']\n",
    "            correction = row['Correction']\n",
    "\n",
    "            # Déterminer la valeur de 'New_Label'\n",
    "            if correction and correction != 'NA':\n",
    "                new_label = correction\n",
    "            else:\n",
    "                new_label = label\n",
    "\n",
    "            # Ajouter la ligne, avec 'New_Label' vide si 'Correction' est 'NA' ou s'il n'y a rien dans 'Label' et 'Correction'\n",
    "            if correction == 'NA':\n",
    "                new_label = ''\n",
    "            elif not label and not correction:\n",
    "                new_label = ''\n",
    "\n",
    "            rows.append({'Token': token, 'Label': new_label})\n",
    "\n",
    "    # Sauvegarder le nouveau fichier CSV dans le dossier de sortie\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    result_df.to_csv(output_path, sep=';', index=False, encoding='utf-8')"
   ],
   "metadata": {
    "id": "06HHxQV4U6t-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718785384488,
     "user_tz": -120,
     "elapsed": 282,
     "user": {
      "displayName": "Camille F",
      "userId": "07170788391818516825"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-10-26T07:45:47.336528Z",
     "start_time": "2024-10-26T07:45:47.328776Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Parcourir récursivement le dossier principal et ses sous-dossiers\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            print(file)\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            # Créer le nouveau chemin de fichier dans le dossier de sortie\n",
    "            relative_path = os.path.relpath(file_path, root_dir)\n",
    "            new_file_path = os.path.join(output_dir, relative_path + '.aia.csv')\n",
    "\n",
    "            # Créer les sous-dossiers nécessaires dans le dossier de sortie\n",
    "            new_file_dir = os.path.dirname(new_file_path)\n",
    "            if not os.path.exists(new_file_dir):\n",
    "                os.makedirs(new_file_dir)\n",
    "\n",
    "            # Traiter le fichier CSV\n",
    "            process_csv_file(file_path, new_file_path)"
   ],
   "metadata": {
    "id": "Jp7xeNzWSXiq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1718785424714,
     "user_tz": -120,
     "elapsed": 22392,
     "user": {
      "displayName": "Camille F",
      "userId": "07170788391818516825"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-10-26T07:49:17.444937Z",
     "start_time": "2024-10-26T07:49:16.014814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA_CARRAUD_petite-Jeanne_Kraken-base_spaCy3.7.2-lg.csv\n",
      "AA_CARRAUD_petite-Jeanne_REF_spaCy3.7.2-lg.csv\n",
      "AA_CARRAUD_petite-Jeanne_TesseractFra-PNG_spaCy3.7.2-lg.csv\n",
      "AA_DAUDET_petit-chose_Kraken-base_spaCy3.7.2-lg.csv\n",
      "AA_DAUDET_petit-chose_TesseractFra-PNG_spaCy3.7.2-lg.csv\n",
      "AA_DAUDET_petit-chose_REF_spaCy3.7.2-lg.csv\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "MNCjeVeglrkY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "eWmQj_wzlrcH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "P3luVRL3SXkv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Fonction pour traiter chaque fichier CSV\n",
    "def process_csv_file(file_path, output_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file, delimiter=';')\n",
    "        rows = []\n",
    "\n",
    "        for row in reader:\n",
    "            token = row['Token']\n",
    "            label = row['Label']\n",
    "            correction = row['Correction']\n",
    "\n",
    "            # Déterminer la valeur de 'New_Label'\n",
    "            if correction and correction != 'NA':\n",
    "                new_label = correction\n",
    "            else:\n",
    "                new_label = label\n",
    "\n",
    "            # Ajouter la ligne si 'New_Label' n'est pas vide et si 'Correction' n'est pas 'NA'\n",
    "            if new_label and new_label != 'NA' and correction != 'NA':\n",
    "                rows.append({'Token': token, 'Label': new_label})\n",
    "\n",
    "    # Sauvegarder le nouveau fichier CSV dans le dossier de sortie\n",
    "    result_df = pd.DataFrame(rows)\n",
    "    result_df.to_csv(output_path, sep=';', index=False, encoding='utf-8')\n"
   ],
   "metadata": {
    "id": "kEufeztlNSjJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Parcourir récursivement le dossier principal et ses sous-dossiers\n",
    "for subdir, dirs, files in os.walk(root_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(subdir, file)\n",
    "            # Créer le nouveau chemin de fichier dans le dossier de sortie\n",
    "            relative_path = os.path.relpath(file_path, root_dir)\n",
    "            new_file_path = os.path.join(output_dir, relative_path + '.aia.csv')\n",
    "\n",
    "            # Créer les sous-dossiers nécessaires dans le dossier de sortie\n",
    "            new_file_dir = os.path.dirname(new_file_path)\n",
    "            if not os.path.exists(new_file_dir):\n",
    "                os.makedirs(new_file_dir)\n",
    "\n",
    "            # Traiter le fichier CSV\n",
    "            process_csv_file(file_path, new_file_path)"
   ],
   "metadata": {
    "id": "R8eJ4v70NSmS"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
